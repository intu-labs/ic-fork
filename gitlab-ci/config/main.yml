no-interrupt:
  extends:
    - .ubuntu-cargo-k8s
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
  interruptible: False
  script:
    - echo "This pipeline is not interruptible"

cargo-audit:
  extends:
    - .ubuntu-cargo-k8s
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "cargo-audit"'
  script:
    - cd rs; cargo audit

boundary-node-service-worker:
  extends:
    - .ubuntu-cargo-k8s
  needs: []
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"'
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"'
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^rc--/'
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_TAG =~ /^service-worker_v([0-9\.]+)$/'
    - if: '$CI_PARENT_PIPELINE_SOURCE == "trigger"'
  stage: test
  script:
    - |
      set -eExuo pipefail
      # shellcheck disable=SC1090
      source "$NVM_DIR/nvm.sh"
      nvm use 18
      node --version
      npm --version

      (
        cd typescript/service-worker
        npm ci
        npm run lint
        npm run format:check
        npm test
        npm run build
        npm run build-dev
        npm pack
        mkdir artifacts
        mv dfinity-service-worker-*.tgz artifacts
        cd artifacts
        sha256sum dfinity-service-worker-*.tgz > SHA256SUMS
      )

      ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}
      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/find-build-id.sh)
      buildevents cmd "${ROOT_PIPELINE_ID}" "${CI_JOB_ID}" rclone -- \
        gitlab-ci/src/artifacts/rclone_upload.py --version="${GIT_REVISION}" "typescript/service-worker/artifacts" service-worker
  artifacts:
    reports:
      junit: typescript/service-worker/junit.xml
    paths:
      - typescript/service-worker/artifacts

.after-script-test:
  extends:
    - .bazel-build-k8s
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - gitlab-ci/src/after_script/**/*
        - gitlab-ci/config/**/*
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE == "merge_train"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\bhotfix\b/i'
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"'
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^rc--/'
  needs: []  # don't wait on other jobs
  tags:
    - dfinity-ic # we do not want the zh tag
  script:
    - |
      set -eExuo pipefail

      cd "${CI_PROJECT_DIR}"

      shellcheck -x gitlab-ci/src/after_script/*.sh

      buildevents cmd "$CI_PIPELINE_ID" "$CI_JOB_ID" "$CI_JOB_NAME" -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

after-script-test-ic-build-legacy-image:
  extends:
    - .after-script-test
    - .ic-build-legacy-image

after-script-test-ic-build-image:
  extends:
    - .after-script-test

bazel-build-fuzzers:
  extends:
    - .bazel-test-all
  variables:
    BAZEL_EXTRA_ARGS: "--repository_cache=/cache/bazel --keep_going --config=fuzzing"
    BAZEL_COMMAND: "build"
    BAZEL_TARGETS: "//rs/..."

bazel-build-fuzzers-weekly:
  extends:
    - .bazel-test-all
    - .ic-build-legacy-image
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "build-fuzzers-to-clusterfuzz"'
  needs: []  # don't wait on other jobs
  script:
    - |
      set -euo pipefail
      cd "${CI_PROJECT_DIR}"/bin
      gcloud auth activate-service-account --key-file "${FUZZING_GCP_SERVICE_KEY}"
      ./build-all-fuzzers.sh --zip
      cd fuzzer_build
      gsutil -m cp libfuzzer_linux_*.zip gs://ic_fuzzer_builds

bazel-build-fuzzers-archives:
  extends:
    - .bazel-test-all
    - .ic-build-legacy-image
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - gitlab-ci/config/20--test--bazel-fuzzers.yml
        - bin/build-all-fuzzers.sh
        - bazel/fuzz_testing.bzl
  needs: []  # don't wait on other jobs
  script:
    - |
      set -euo pipefail
      cd "${CI_PROJECT_DIR}"/bin
      ./build-all-fuzzers.sh --zip

.bazel-rules-pipeline:
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE == "merge_train"'
      variables:
        BAZEL_EXTRA_ARGS_RULES: "--test_timeout_filters=short,moderate"
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\bhotfix\b/i'
      variables:
        BAZEL_EXTRA_ARGS_RULES: "--test_timeout_filters=short,moderate"
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"'
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^rc--/'

.bazel-rules-pipeline-no-merge-train:
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train" && $CI_MERGE_REQUEST_TITLE =~ /\bhotfix\b/i'
      variables:
        BAZEL_EXTRA_ARGS_RULES: "--test_timeout_filters=short,moderate"
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"'
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"'
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^rc--/'

.bazel-rules-pipeline-no-merge-train-allow-to-fail:
  rules:
    # Set to manual due to capacity crunch 2022-12-13.
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"'
      when: manual
      allow_failure: true
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"'
      allow_failure: true
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^rc--/'
      allow_failure: true

.bazel-rules-post-master:
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"'
      when: manual
      allow_failure: true
    - if: '$SCHEDULE_NAME == "run-all-master"'

.bazel-test-all:
  extends:
    - .bazel-rules-pipeline
    - .bazel-build-k8s
  needs: []
  artifacts:
    when: always
    paths:
      - bazel-build-log*.json*
      - bazel-bep.pb
    reports:
      junit: bazel-testlogs-gitlab/**/test.xml
  variables:
    BAZEL_COMMAND: "test"
    BAZEL_TARGETS: "//..."
  script:
    - ./gitlab-ci/src/bazel-ci/main.sh
  after_script:
    - |
      set +e # Do not fail in the after_script, try to do as much as possible instead.
      echo -e "\033[0;31m"
      echo -e "************************************************************************"
      echo -e "*** NEED BAZEL HELP? See go/bazel-guide and #project-bazel           ***"
      echo -e "*** (NEW) To regenerate Cargo Bazel lockfiles run ./bin/bazel-pin.sh ***"
      echo -e "************************************************************************"
      echo -e "\033[0m"
    - cp -R "$(realpath bazel-testlogs)" bazel-testlogs-gitlab
    - gzip bazel-build-log*.json
    - |
      echo -e "\e[0Ksection_start:$(date +%s):bazel_exporter_logs[collapsed=true]\r\e[0KClick to see Bazel exporter logs"
      bazel run //bazel/exporter:exporter --build_event_binary_file= -- -f "$(pwd)/bazel-bep.pb"
      echo -e "\e[0Ksection_end:$(date +%s):bazel_exporter_logs\r\e[0K"
    - !reference [after_script]

bazel-test-all:
  extends:
    - .bazel-test-all
  variables:
    BAZEL_EXTRA_ARGS: "--repository_cache=/cache/bazel --keep_going $BAZEL_EXTRA_ARGS_RULES"
    BAZEL_TARGETS: "//..."
  timeout: 80 minutes

linux-openssl-static-binaries:
  extends:
    - .bazel-test-all
    - .bazel-rules-pipeline-no-merge-train
  variables:
    DFINITY_OPENSSL_STATIC: 1
    BAZEL_COMMAND: "build"
    BAZEL_TARGETS: "//publish/binaries:upload"

# VER-1818: bazelified system tests should not block pre-master pipelines, as they run on a new (WIP) test driver implementation.
bazel-test-all-allow-to-fail:
  extends:
    - .bazel-test-all
    - .bazel-rules-pipeline-no-merge-train-allow-to-fail
  variables:
    BAZEL_EXTRA_ARGS: "--repository_cache=/cache/bazel --keep_going --test_tag_filters=allow_to_fail"
    BAZEL_TARGETS: "//..."

bazel-system-test-hourly:
  extends:
    - .bazel-test-all
    - .bazel-rules-post-master
  variables:
    BAZEL_EXTRA_ARGS: "--repository_cache=/cache/bazel --test_tag_filters=system_test_hourly"
    BAZEL_TARGETS: "//..."
  timeout: 120 minutes

bazel-system-test-hotfix:
  extends:
    - .bazel-test-all
    - .rules-prod-hotfix-pipeline
  variables:
    BAZEL_EXTRA_ARGS: "--repository_cache=/cache/bazel --test_tag_filters=system_test_hotfix"
    BAZEL_TARGETS: "//..."

bazel-system-test-staging:
  extends:
    - .bazel-test-all
    - .rules-rollout-pipeline-auto
  variables:
    BAZEL_EXTRA_ARGS: "--repository_cache=/cache/bazel --test_tag_filters=system_test_staging"
    BAZEL_TARGETS: "//..."
  allow_failure: true

bazel-system-test-nightly:
  extends:
    - .bazel-test-all
    - .rules-rollout-pipeline-auto
  variables:
    BAZEL_EXTRA_ARGS: "--repository_cache=/cache/bazel --test_tag_filters=system_test_nightly"
    BAZEL_TARGETS: "//..."
  timeout: 7h 30m

bazel-config-check-all-rebuild:
  extends:
    - .bazel-test-all
  variables:
    BAZEL_EXTRA_ARGS: "--repository_cache=/cache/bazel --keep_going --config=check"
    BAZEL_COMMAND: "build"
    BAZEL_TARGETS: "//rs/..."

bazel-test-all-rebuild:
  extends:
    - .bazel-test-all
    - .bazel-rules-post-master
  variables:
    BAZEL_COMMAND: "build"
    BAZEL_EXTRA_ARGS: "--repository_cache= --disk_cache= --noremote_accept_cached --remote_instance_name=${CI_COMMIT_SHA} --@rules_rust//rust/settings:pipelined_compilation=True"
  timeout: 2h

bazel-build-macos:
  extends:
    - .build-env-base
    - .bazel-test-all
    - .bazel-rules-pipeline-no-merge-train
  tags:
    - macos
  variables:
    BAZEL_STARTUP_ARGS: "--output_base /var/tmp/bazel-output//${CI_CONCURRENT_ID}"
    BAZEL_COMMAND: "build"
    BAZEL_EXTRA_ARGS: "--config macos_ci"
    BAZEL_TARGETS: "//rs/... //publish/binaries/..."
  timeout: 90 minutes

macos-openssl-static-binaries:
  extends:
    - .build-env-base
    - .bazel-test-all
    - .bazel-rules-pipeline-no-merge-train
  tags:
    - macos
  variables:
    DFINITY_OPENSSL_STATIC: 1
    BAZEL_STARTUP_ARGS: "--output_base /var/tmp/bazel-output//${CI_CONCURRENT_ID}"
    BAZEL_COMMAND: "build"
    BAZEL_EXTRA_ARGS: "--config macos_ci"
    BAZEL_TARGETS: "//publish/binaries:upload"
  script:
    - !reference [.bazel-test-all, script]
    - |
      # check replica
      if ! bazel run --config macos_ci //publish/binaries:replica -- --print-sample-config --replica-version 1 >/dev/null; then
        BIN=$(bazel cquery --output=files //publish/binaries:replica)
        otool -L "$BIN"
        exit 1
      fi
      # check ic-starter
      if ! bazel run --config macos_ci //publish/binaries:ic-starter -- --version; then
        BIN=$(bazel cquery --output=files //publish/binaries:ic-starter)
        otool -L "$BIN"
        exit 1
      fi

.build-ic:
  extends:
    - .ic-build-image
  needs: []
  artifacts:
    reports:
      dotenv: nns.release.env
    paths:
      - bazel-build-log*.json*
  script:
    - |
      set -euo pipefail
      VERSION=$(git rev-parse HEAD)

      if [ "$CI_JOB_NAME" == "build-ic-release" ]; then
          # read NNS release version from git tree
          NNS_RELEASE_VERSION="$(jq -r '.subnets["tdb26-jop6k-aogll-7ltgs-eruif-6kk7m-qpktf-gdiqx-mxtrf-vb5e6-eqe"]' testnet/mainnet_revisions.json)"
          # we pass nss version info to build-determinism-*-release jobs
          # we put it under /tmp due to git clean -ffdx within build-ic script
          echo "NNS_RELEASE_VERSION=$NNS_RELEASE_VERSION" > /tmp/nns.release.env

          # fetch and checkout this version
          git fetch origin "$NNS_RELEASE_VERSION"
          git checkout "$NNS_RELEASE_VERSION"
          # NOTE: ic/$VERSION in S3 will have artifacts
          #       for revision $NNS_RELEASE_VERSION !!!
      fi

      if [ "$CI_COMMIT_REF_PROTECTED" == "true" ]; then
          gitlab-ci/container/build-ic.sh -i -c -b
      else
          gitlab-ci/container/build-ic.sh -i -c -b --no-release
      fi

      # release binaries
      buildevents cmd "${ROOT_PIPELINE_ID}" "${CI_JOB_ID}" rclone -- \
          gitlab-ci/src/artifacts/rclone_upload.py --version="${VERSION}" \
          "artifacts/release" "${CI_JOB_NAME}/release"
      # canister binaries
      buildevents cmd "${ROOT_PIPELINE_ID}" "${CI_JOB_ID}" rclone -- \
          gitlab-ci/src/artifacts/rclone_upload.py --version="${VERSION}" \
          "artifacts/canisters" "${CI_JOB_NAME}/canisters"

      # guestos images
      buildevents cmd "${ROOT_PIPELINE_ID}" "${CI_JOB_ID}" rclone -- \
          gitlab-ci/src/artifacts/rclone_upload.py --version="${VERSION}" \
          "artifacts/icos/guestos" "${CI_JOB_NAME}/guest-os"
      # hostos images
      buildevents cmd "${ROOT_PIPELINE_ID}" "${CI_JOB_ID}" rclone -- \
          gitlab-ci/src/artifacts/rclone_upload.py --version="${VERSION}" \
          "artifacts/icos/hostos" "${CI_JOB_NAME}/host-os"
      # setupos images
      buildevents cmd "${ROOT_PIPELINE_ID}" "${CI_JOB_ID}" rclone -- \
          gitlab-ci/src/artifacts/rclone_upload.py --version="${VERSION}" \
          "artifacts/icos/setupos" "${CI_JOB_NAME}/setup-os"

      # collect dotenv
      if [ -f /tmp/nns.release.env ]; then
          mv /tmp/nns.release.env .
      fi

# MR Pipeline
build-ic:
  extends:
    - .build-ic
    - .bazel-rules-pipeline

# Scheduled Pipeline
build-ic-release:
  extends:
    - .build-ic
    - .rules-scheduled-reproducibility

cargo-lock-generate:
  extends:
    - .ubuntu-cargo-k8s
    - .cargo-rules
  needs: []  # don't wait on other jobs
  script:
    - |
      echo "Running a tiny cargo check (should always succeed), just to make sure Cargo.lock is up to date"
      set -exuo pipefail
      cd "${CI_PROJECT_DIR}"
      cargo check -p ic-sys
      cd "${CI_PROJECT_DIR}"
    - |
      set -exuo pipefail
      git add Cargo.lock
      git status
      if ! git diff --cached --quiet; then
        # If a merge request and not on a merge train then update the Cargo.lock file in the MR automatically.
        if [ "$CI_PIPELINE_SOURCE" = "merge_request_event" ]  && [ "$CI_MERGE_REQUEST_EVENT_TYPE" != "merge_train" ];then
          # There are some changes staged
          # Command might fail because the gitlab remote already exists from a previous run.
          git remote add origin "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git" || true
          git remote set-url origin "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git" || true
          git config --global user.email "infra+gitlab-automation@dfinity.org"
          git config --global user.name "IDX GitLab Automation"
          git commit -m"Automatically updated Cargo.lock"
          git push origin HEAD:"${CI_COMMIT_REF_NAME}"
        fi

        # Force the pipeline to fail so MRs cannot be merged with a stale cargo lockfile.
        exit 1
      fi

pre-commit:
  variables:
    # Set the pre-commit home to this directory so we can cache it
    # more easily.
    PRE_COMMIT_HOME: /cache/pre-commit/$CI_CONCURRENT_ID
  extends:
    - .bazel-build-k8s
    - .bazel-rules-pipeline
  needs: []  # don't wait on other jobs
  tags:
    - dfinity-ic # overwritting so we do not inherit the zh tag
  script:
    - |
      set -eEuo pipefail

      rustup default stable

      # Make sure CI can pull from the private repo.
      if ! SKIP=bazel_rust_format_check,bazel_smoke pre-commit run -a --hook-stage=manual ; then
        echo "Pre-commit checks failed. Here is the diff of the changes:"
        git diff
        echo
        echo "You can fix the code locally by following these instructions in the same branch."
        echo
        echo "install pre-commit by following https://pre-commit.com/#installation:"
        echo "(brew|pip) install pre-commit"
        echo "pre-commit install"
        echo
        echo "Then, to fix the checks in this branch, run:"
        echo "pre-commit run --from-ref=\$(git merge-base HEAD master) --to-ref=HEAD"
        echo
        echo "And then commit the changes."
        exit 1
      fi
